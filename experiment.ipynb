{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ef581bdb7d6e47849e5983c0104bd1ea",
    "deepnote_cell_type": "markdown",
    "id": "ewhyFqhtxLZr"
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": "3d1cc0bae4934bf6a226d3fd0e662022",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 28,
    "execution_start": 1681025738069,
    "id": "jgiAa62vETd-",
    "outputId": "3593ab81-608a-4e84-eacd-0a207d0376a5",
    "source_hash": "e837903e"
   },
   "outputs": [],
   "source": [
    "# # Import libraries\n",
    "# !pip install py_stringsimjoin\n",
    "# !pip install py_stringmatching\n",
    "import json, copy, os, time\n",
    "import pandas as pd\n",
    "import py_stringmatching as sm\n",
    "import py_stringsimjoin as ssj\n",
    "from py_stringmatching.tokenizer.delimiter_tokenizer import DelimiterTokenizer\n",
    "from py_stringmatching.tokenizer.qgram_tokenizer import QgramTokenizer\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a5fc7955cb7b43a38ff50f5c16b0b098",
    "deepnote_cell_type": "markdown",
    "id": "JHpWmihVxWCq"
   },
   "source": [
    "# Define measure and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "67c89af5fd2a48079c36dbe2d769ac05",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1681025738328,
    "id": "hoM6M95onRDT",
    "source_hash": "2451014b"
   },
   "outputs": [],
   "source": [
    "TOKENIZERS = {'SPACE_DELIMITER': DelimiterTokenizer(delim_set={' '}, return_set=True),\n",
    "              '2_GRAM': QgramTokenizer(qval=2, padding=False, return_set=True),\n",
    "              '3_GRAM': QgramTokenizer(qval=3, padding=False, return_set=True),\n",
    "              '4_GRAM': QgramTokenizer(qval=4, padding=False, return_set=True),\n",
    "              '5_GRAM': QgramTokenizer(qval=5, padding=False, return_set=True),\n",
    "              '2_GRAM_BAG': QgramTokenizer(qval=2),\n",
    "              '3_GRAM_BAG': QgramTokenizer(qval=3)\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "905cbdc7f9644123829996c94bbd613b",
    "deepnote_cell_type": "markdown",
    "id": "Gt7xduvIx8ce"
   },
   "source": [
    "# Define filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "227a5bfcc3734d27beba17c0edfb1a20",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1681025738328,
    "id": "Z3oL9Sr4nr5U",
    "source_hash": "ab932efc"
   },
   "outputs": [],
   "source": [
    "FILTERS = {\n",
    "    \"OVERLAP_FILTER\": ssj.OverlapFilter,\n",
    "    \"SIZE_FILTER\": ssj.SizeFilter,\n",
    "    \"PREFIX_FILTER\": ssj.PrefixFilter,\n",
    "    \"POSITION_FILTER\": ssj.PositionFilter,\n",
    "    \"SUFFIX_FILTER\": ssj.SuffixFilter\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "56e7f9ddabd840eebeb44ef8311acf48",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Define string similarity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "44efb54c585a4e7da02c046936cb4b24",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1681025738378,
    "source_hash": "83926d71"
   },
   "outputs": [],
   "source": [
    "SIM_FUNC = {\n",
    "    'COSINE': sm.Cosine().get_sim_score,\n",
    "    'DICE': sm.Dice().get_sim_score,\n",
    "    'JACCARD': sm.Jaccard().get_sim_score,\n",
    "    'OVERLAP_COEFFICIENT': sm.OverlapCoefficient().get_sim_score,\n",
    "    'LEVENSHTEIN': sm.Levenshtein().get_sim_score,\n",
    "    'TF-IDF': sm.TfIdf,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "930899e860a04c3890d013a72df5433e",
    "deepnote_cell_type": "markdown",
    "id": "hwWsTSjpyAFU"
   },
   "source": [
    "# Define directory and load script function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": "7bea85508a6b4b6bab38993d7d200ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1681025738450,
    "id": "J-VYzWpDncyZ",
    "source_hash": "cb516d1c"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = os.sep.join([os.getcwd(), 'dataset'])\n",
    "BENCHMARK_DIRECTORY = 'benchmark_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scripts(scripts_file_name):\n",
    "    with open(scripts_file_name, 'r') as js_file:\n",
    "        scripts = json.load(js_file)['scripts']\n",
    "    return scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply each testing configuration for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(script, l_table, r_table, idx_script, scripts_file_name):\n",
    "    result = []\n",
    "    total_info_obj = product(script['sim_funcs'], script['sim_measure_types'],\n",
    "                            script['tokenizers'], script['scale_filters'],\n",
    "                            script['thresholds'], script['n_jobs'])\n",
    "    for sim_funcs, sim_measure_type, tokenizer, scale_filter, threshold, n_jobs in total_info_obj:\n",
    "        if tokenizer in [\"SPACE_DELIMITER\"] and sim_measure_type != 'EDIT_DISTANCE':\n",
    "            continue\n",
    "        sim_func = SIM_FUNC[sim_funcs]\n",
    "        tok = TOKENIZERS[tokenizer]\n",
    "        if scale_filter == \"OVERLAP_FILTER\":\n",
    "            s_filter = FILTERS[scale_filter](tok, overlap_size=1, comp_op='>=', allow_missing=False)\n",
    "        else:\n",
    "            s_filter = FILTERS[scale_filter](tok, sim_measure_type, threshold, allow_empty=True, allow_missing=False)\n",
    "        sum_time = 0\n",
    "        start_time = time.time()\n",
    "        print(s_filter)\n",
    "        candidate_set = s_filter.filter_tables(\n",
    "            l_table, r_table,\n",
    "            script['l_id_attr'], script['r_id_attr'],\n",
    "            script['l_join_attr'], script['r_join_attr'],\n",
    "            l_out_attrs=None, r_out_attrs=None,\n",
    "            l_out_prefix='l_', r_out_prefix='r_',\n",
    "            n_jobs=n_jobs, show_progress=False)\n",
    "        output_table = ssj.apply_matcher(candidate_set,\n",
    "                                        'l_' + script['l_id_attr'], 'r_' + script['r_id_attr'], l_table, r_table,\n",
    "                                        script['l_id_attr'], script['r_id_attr'],\n",
    "                                        script['l_join_attr'], script['r_join_attr'],\n",
    "                                        tokenizer=tok, sim_function=sim_func, threshold=threshold,\n",
    "                                        comp_op='>=', allow_missing=True,\n",
    "                                        l_out_attrs=[script['l_join_attr']], r_out_attrs=[script['r_join_attr']],\n",
    "                                        l_out_prefix='l_', r_out_prefix='r_',\n",
    "                                        out_sim_score=True, n_jobs=n_jobs, show_progress=False)\n",
    "        sum_time += (time.time() - start_time)\n",
    "        cand_set_size = len(candidate_set)\n",
    "        if not os.path.exists(BENCHMARK_DIRECTORY):\n",
    "            os.makedirs(BENCHMARK_DIRECTORY)\n",
    "        if not os.path.exists(os.sep.join([BENCHMARK_DIRECTORY, str(idx_script)])):\n",
    "            os.makedirs(os.sep.join([BENCHMARK_DIRECTORY, str(idx_script)]))\n",
    "        output_table.to_csv(os.sep.join([BENCHMARK_DIRECTORY, str(idx_script),\n",
    "            scripts_file_name + sim_measure_type + '_' + tokenizer + str(threshold) + '_' + str(n_jobs) + scale_filter + '_' + sim_funcs + '_' + str(idx_script) + '.csv']))\n",
    "        obj_res = {\"idx_script\" : idx_script, \"table\": copy.deepcopy(output_table), \"time\" : sum_time, \"num_candidate\": cand_set_size}\n",
    "        result.append(obj_res)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": "fdcf47b793314724a0fed1c7b324acd1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 24,
    "execution_start": 1681025738468,
    "id": "FYe91P2jqaR9",
    "source_hash": "cce324b3"
   },
   "outputs": [],
   "source": [
    "def load_data_and_test(scripts_file_name):\n",
    "    result = []\n",
    "    scripts = load_scripts(scripts_file_name)\n",
    "    for idx, script in enumerate(scripts):\n",
    "        l_path = os.sep.join([DATA_PATH, *script['ltable']])\n",
    "        r_path = os.sep.join([DATA_PATH, *script['rtable']])\n",
    "        l_table = pd.read_csv(l_path, encoding=script['ltable_encoding'])\n",
    "        r_table = pd.read_csv(r_path, encoding=script['rtable_encoding'])\n",
    "        result.append(test(script, l_table, r_table, idx, scripts_file_name))\n",
    "    return result, l_table, r_table\n",
    "#result là mảng chiều: chiều thứ nhất tương ứng với chỉ số script trong list các script\n",
    "#chiều thứ hai là dictionary ứng với từng lần đo trong mỗi script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<py_stringsimjoin.filter.position_filter.PositionFilter object at 0x0000014EEF889F90>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\py_stringsimjoin\\utils\\generic_helper.py:76: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only.\n",
      "  projected_dataframe = dataframe[proj_attrs].dropna(0,\n",
      "c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\py_stringsimjoin\\utils\\generic_helper.py:76: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only.\n",
      "  projected_dataframe = dataframe[proj_attrs].dropna(0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<py_stringsimjoin.filter.position_filter.PositionFilter object at 0x0000014EEED39900>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\py_stringsimjoin\\utils\\generic_helper.py:76: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only.\n",
      "  projected_dataframe = dataframe[proj_attrs].dropna(0,\n",
      "c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\py_stringsimjoin\\utils\\generic_helper.py:76: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only.\n",
      "  projected_dataframe = dataframe[proj_attrs].dropna(0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<py_stringsimjoin.filter.position_filter.PositionFilter object at 0x0000014EEF897250>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\py_stringsimjoin\\utils\\generic_helper.py:76: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only.\n",
      "  projected_dataframe = dataframe[proj_attrs].dropna(0,\n",
      "c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\py_stringsimjoin\\utils\\generic_helper.py:76: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only.\n",
      "  projected_dataframe = dataframe[proj_attrs].dropna(0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<py_stringsimjoin.filter.position_filter.PositionFilter object at 0x0000014EE9798850>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\py_stringsimjoin\\utils\\generic_helper.py:76: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only.\n",
      "  projected_dataframe = dataframe[proj_attrs].dropna(0,\n",
      "c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\py_stringsimjoin\\utils\\generic_helper.py:76: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only.\n",
      "  projected_dataframe = dataframe[proj_attrs].dropna(0,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<py_stringsimjoin.filter.position_filter.PositionFilter object at 0x0000014EECAEB820>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\py_stringsimjoin\\utils\\generic_helper.py:76: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only.\n",
      "  projected_dataframe = dataframe[proj_attrs].dropna(0,\n",
      "c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\py_stringsimjoin\\utils\\generic_helper.py:76: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only.\n",
      "  projected_dataframe = dataframe[proj_attrs].dropna(0,\n"
     ]
    }
   ],
   "source": [
    "result, l_table, r_table = load_data_and_test(\"scripts_1.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show an example of joined result "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left table, right table before join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>journals/sigmod/Mackay99</td>\n",
       "      <td>Semantic Integration of Environmental Models for Application to Global Information Systems and D...</td>\n",
       "      <td>D. Scott Mackay</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conf/vldb/PoosalaI96</td>\n",
       "      <td>Estimation of Query-Result Distribution and its Application in Parallel-Join Load Balancing</td>\n",
       "      <td>Viswanath Poosala, Yannis E. Ioannidis</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conf/vldb/PalpanasSCP02</td>\n",
       "      <td>Incremental Maintenance for Non-Distributive Aggregate Functions</td>\n",
       "      <td>Themistoklis Palpanas, Richard Sidle, Hamid Pirahesh, Roberta Cochrane</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>conf/vldb/GardarinGT96</td>\n",
       "      <td>Cost-based Selection of Path Expression Processing Algorithms in Object-Oriented Databases</td>\n",
       "      <td>Zhao-Hui Tang, Georges Gardarin, Jean-Robert Gruser</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conf/vldb/HoelS95</td>\n",
       "      <td>Benchmarking Spatial Join Operations with Spatial Output</td>\n",
       "      <td>Erik G. Hoel, Hanan Samet</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>journals/tods/KarpSP03</td>\n",
       "      <td>A simple algorithm for finding frequent elements in streams and bags</td>\n",
       "      <td>Scott Shenker, Christos H. Papadimitriou, Richard M. Karp</td>\n",
       "      <td>ACM Trans. Database Syst.</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>conf/vldb/LimWV03</td>\n",
       "      <td>SASH: A Self-Adaptive Histogram Set for Dynamically Changing Workloads</td>\n",
       "      <td>Lipyeow Lim, Min Wang, Jeffrey Scott Vitter</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>journals/tods/ChakrabartiKMP02</td>\n",
       "      <td>Locally adaptive dimensionality reduction for indexing large time series databases</td>\n",
       "      <td>Kaushik Chakrabarti, Eamonn J. Keogh, Michael J. Pazzani, Sharad Mehrotra</td>\n",
       "      <td>ACM Trans. Database Syst.</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>journals/sigmod/Snodgrass01</td>\n",
       "      <td>Chair's Message</td>\n",
       "      <td>Richard T. Snodgrass</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>conf/vldb/LiM01</td>\n",
       "      <td>Indexing and Querying XML Data for Regular Path Expressions</td>\n",
       "      <td>Bongki Moon, Quanzhong Li</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2616 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  \\\n",
       "0           journals/sigmod/Mackay99   \n",
       "1               conf/vldb/PoosalaI96   \n",
       "2            conf/vldb/PalpanasSCP02   \n",
       "3             conf/vldb/GardarinGT96   \n",
       "4                  conf/vldb/HoelS95   \n",
       "...                              ...   \n",
       "2611          journals/tods/KarpSP03   \n",
       "2612               conf/vldb/LimWV03   \n",
       "2613  journals/tods/ChakrabartiKMP02   \n",
       "2614     journals/sigmod/Snodgrass01   \n",
       "2615                 conf/vldb/LiM01   \n",
       "\n",
       "                                                                                                    title  \\\n",
       "0     Semantic Integration of Environmental Models for Application to Global Information Systems and D...   \n",
       "1             Estimation of Query-Result Distribution and its Application in Parallel-Join Load Balancing   \n",
       "2                                        Incremental Maintenance for Non-Distributive Aggregate Functions   \n",
       "3              Cost-based Selection of Path Expression Processing Algorithms in Object-Oriented Databases   \n",
       "4                                                Benchmarking Spatial Join Operations with Spatial Output   \n",
       "...                                                                                                   ...   \n",
       "2611                                 A simple algorithm for finding frequent elements in streams and bags   \n",
       "2612                               SASH: A Self-Adaptive Histogram Set for Dynamically Changing Workloads   \n",
       "2613                   Locally adaptive dimensionality reduction for indexing large time series databases   \n",
       "2614                                                                                      Chair's Message   \n",
       "2615                                          Indexing and Querying XML Data for Regular Path Expressions   \n",
       "\n",
       "                                                                        authors  \\\n",
       "0                                                               D. Scott Mackay   \n",
       "1                                        Viswanath Poosala, Yannis E. Ioannidis   \n",
       "2        Themistoklis Palpanas, Richard Sidle, Hamid Pirahesh, Roberta Cochrane   \n",
       "3                           Zhao-Hui Tang, Georges Gardarin, Jean-Robert Gruser   \n",
       "4                                                     Erik G. Hoel, Hanan Samet   \n",
       "...                                                                         ...   \n",
       "2611                  Scott Shenker, Christos H. Papadimitriou, Richard M. Karp   \n",
       "2612                                Lipyeow Lim, Min Wang, Jeffrey Scott Vitter   \n",
       "2613  Kaushik Chakrabarti, Eamonn J. Keogh, Michael J. Pazzani, Sharad Mehrotra   \n",
       "2614                                                       Richard T. Snodgrass   \n",
       "2615                                                  Bongki Moon, Quanzhong Li   \n",
       "\n",
       "                          venue  year  \n",
       "0                 SIGMOD Record  1999  \n",
       "1                          VLDB  1996  \n",
       "2                          VLDB  2002  \n",
       "3                          VLDB  1996  \n",
       "4                          VLDB  1995  \n",
       "...                         ...   ...  \n",
       "2611  ACM Trans. Database Syst.  2003  \n",
       "2612                       VLDB  2003  \n",
       "2613  ACM Trans. Database Syst.  2002  \n",
       "2614              SIGMOD Record  2001  \n",
       "2615                       VLDB  2001  \n",
       "\n",
       "[2616 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304586</td>\n",
       "      <td>The WASA2 object-oriented workflow management system</td>\n",
       "      <td>Gottfried Vossen, Mathias Weske</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304587</td>\n",
       "      <td>A user-centered interface for querying distributed multimedia databases</td>\n",
       "      <td>Isabel F. Cruz, Kimberly M. James</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304589</td>\n",
       "      <td>World Wide Database-integrating the Web, CORBA and databases</td>\n",
       "      <td>Athman Bouguettaya, Boualem Benatallah, Lily Hendra, James Beard, Kevin Smith, Mourad Quzzani</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304590</td>\n",
       "      <td>XML-based information mediation with MIX</td>\n",
       "      <td>Chaitan Baru, Amarnath Gupta, Bertram Lud&amp;#228;scher, Richard Marciano, Yannis Papakonstantinou,...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304582</td>\n",
       "      <td>The CCUBE constraint object-oriented database system</td>\n",
       "      <td>Alexander Brodsky, Victor E. Segal, Jia Chen, Paval A. Exarkhopoulo</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>672977</td>\n",
       "      <td>Dual-Buffering Strategies in Object Bases</td>\n",
       "      <td>Alfons Kemper, Donald Kossmann</td>\n",
       "      <td>Very Large Data Bases</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>950482</td>\n",
       "      <td>Guest editorial</td>\n",
       "      <td>Philip A. Bernstein, Yannis Ioannidis, Raghu Ramakrishnan</td>\n",
       "      <td>The VLDB Journal &amp;mdash; The International Journal on Very Large Data Bases</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>672980</td>\n",
       "      <td>GraphDB: Modeling and Querying Graphs in Databases</td>\n",
       "      <td>Ralf Hartmut G&amp;#252;ting</td>\n",
       "      <td>Very Large Data Bases</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>945741</td>\n",
       "      <td>Review of The data warehouse toolkit: the complete guide to dimensional modeling (2nd edition) b...</td>\n",
       "      <td>Alexander A. Anisimov</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>672979</td>\n",
       "      <td>Bulk Loading into an OODB: A Performance Study</td>\n",
       "      <td>Janet L. Wiener, Jeffrey F. Naughton</td>\n",
       "      <td>Very Large Data Bases</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2294 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "0     304586   \n",
       "1     304587   \n",
       "2     304589   \n",
       "3     304590   \n",
       "4     304582   \n",
       "...      ...   \n",
       "2289  672977   \n",
       "2290  950482   \n",
       "2291  672980   \n",
       "2292  945741   \n",
       "2293  672979   \n",
       "\n",
       "                                                                                                    title  \\\n",
       "0                                                    The WASA2 object-oriented workflow management system   \n",
       "1                                 A user-centered interface for querying distributed multimedia databases   \n",
       "2                                            World Wide Database-integrating the Web, CORBA and databases   \n",
       "3                                                                XML-based information mediation with MIX   \n",
       "4                                                    The CCUBE constraint object-oriented database system   \n",
       "...                                                                                                   ...   \n",
       "2289                                                            Dual-Buffering Strategies in Object Bases   \n",
       "2290                                                                                      Guest editorial   \n",
       "2291                                                   GraphDB: Modeling and Querying Graphs in Databases   \n",
       "2292  Review of The data warehouse toolkit: the complete guide to dimensional modeling (2nd edition) b...   \n",
       "2293                                                       Bulk Loading into an OODB: A Performance Study   \n",
       "\n",
       "                                                                                                  authors  \\\n",
       "0                                                                         Gottfried Vossen, Mathias Weske   \n",
       "1                                                                       Isabel F. Cruz, Kimberly M. James   \n",
       "2           Athman Bouguettaya, Boualem Benatallah, Lily Hendra, James Beard, Kevin Smith, Mourad Quzzani   \n",
       "3     Chaitan Baru, Amarnath Gupta, Bertram Lud&#228;scher, Richard Marciano, Yannis Papakonstantinou,...   \n",
       "4                                     Alexander Brodsky, Victor E. Segal, Jia Chen, Paval A. Exarkhopoulo   \n",
       "...                                                                                                   ...   \n",
       "2289                                                                       Alfons Kemper, Donald Kossmann   \n",
       "2290                                            Philip A. Bernstein, Yannis Ioannidis, Raghu Ramakrishnan   \n",
       "2291                                                                             Ralf Hartmut G&#252;ting   \n",
       "2292                                                                                Alexander A. Anisimov   \n",
       "2293                                                                 Janet L. Wiener, Jeffrey F. Naughton   \n",
       "\n",
       "                                                                             venue  \\\n",
       "0                                   International Conference on Management of Data   \n",
       "1                                   International Conference on Management of Data   \n",
       "2                                   International Conference on Management of Data   \n",
       "3                                   International Conference on Management of Data   \n",
       "4                                   International Conference on Management of Data   \n",
       "...                                                                            ...   \n",
       "2289                                                         Very Large Data Bases   \n",
       "2290  The VLDB Journal &mdash; The International Journal on Very Large Data Bases    \n",
       "2291                                                         Very Large Data Bases   \n",
       "2292                                                            ACM SIGMOD Record    \n",
       "2293                                                         Very Large Data Bases   \n",
       "\n",
       "      year  \n",
       "0     1999  \n",
       "1     1999  \n",
       "2     1999  \n",
       "3     1999  \n",
       "4     1999  \n",
       "...    ...  \n",
       "2289  1994  \n",
       "2290  2003  \n",
       "2291  1994  \n",
       "2292  2003  \n",
       "2293  1994  \n",
       "\n",
       "[2294 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of a joined-table using Position Filter, threshold 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>l_id</th>\n",
       "      <th>r_id</th>\n",
       "      <th>l_title</th>\n",
       "      <th>r_title</th>\n",
       "      <th>_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177</td>\n",
       "      <td>conf/sigmod/BouguettayaBH99</td>\n",
       "      <td>304589</td>\n",
       "      <td>World Wide Database - Integrating the Web, CORBA, and Databases</td>\n",
       "      <td>World Wide Database-integrating the Web, CORBA and databases</td>\n",
       "      <td>0.811321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>225</td>\n",
       "      <td>conf/sigmod/BaruGLMPVC99</td>\n",
       "      <td>304590</td>\n",
       "      <td>XML-Based Information Mediation with MIX</td>\n",
       "      <td>XML-based information mediation with MIX</td>\n",
       "      <td>0.710526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>362</td>\n",
       "      <td>conf/sigmod/RoussopoulosKS99</td>\n",
       "      <td>304584</td>\n",
       "      <td>The Active MultiSync Controller of the Cubetree Storage Organization</td>\n",
       "      <td>The active MultiSync controller of the cubetree storage organization</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>932</td>\n",
       "      <td>journals/sigmod/Danish98</td>\n",
       "      <td>306103</td>\n",
       "      <td>Building Database-driven Electronic Catalogs</td>\n",
       "      <td>Building database-driven electronic catalogs</td>\n",
       "      <td>0.744681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>985</td>\n",
       "      <td>journals/sigmod/MeltzerC98</td>\n",
       "      <td>306105</td>\n",
       "      <td>XML and Electronic Commerce: Enabling the Network Economy</td>\n",
       "      <td>XML and electronic commerce: enabling the network economy</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>152672</td>\n",
       "      <td>journals/vldb/AbbadiSW01</td>\n",
       "      <td>950482</td>\n",
       "      <td>Guest editorial</td>\n",
       "      <td>Guest editorial</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>152673</td>\n",
       "      <td>journals/vldb/Atkinson00</td>\n",
       "      <td>950482</td>\n",
       "      <td>Guest editorial</td>\n",
       "      <td>Guest editorial</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>152674</td>\n",
       "      <td>conf/vldb/Guting94</td>\n",
       "      <td>672980</td>\n",
       "      <td>GraphDB: Modeling and Querying Graphs in Databases</td>\n",
       "      <td>GraphDB: Modeling and Querying Graphs in Databases</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>152702</td>\n",
       "      <td>journals/sigmod/Anisimov03</td>\n",
       "      <td>945741</td>\n",
       "      <td>Review of The data warehouse toolkit: the complete guide to dimensional modeling (2nd edition) b...</td>\n",
       "      <td>Review of The data warehouse toolkit: the complete guide to dimensional modeling (2nd edition) b...</td>\n",
       "      <td>0.992126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>152704</td>\n",
       "      <td>conf/vldb/WienerN94</td>\n",
       "      <td>672979</td>\n",
       "      <td>Bulk Loading into an OODB: A Performance Study</td>\n",
       "      <td>Bulk Loading into an OODB: A Performance Study</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1737 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _id                          l_id    r_id  \\\n",
       "0       177   conf/sigmod/BouguettayaBH99  304589   \n",
       "1       225      conf/sigmod/BaruGLMPVC99  304590   \n",
       "2       362  conf/sigmod/RoussopoulosKS99  304584   \n",
       "3       932      journals/sigmod/Danish98  306103   \n",
       "4       985    journals/sigmod/MeltzerC98  306105   \n",
       "..      ...                           ...     ...   \n",
       "365  152672      journals/vldb/AbbadiSW01  950482   \n",
       "366  152673      journals/vldb/Atkinson00  950482   \n",
       "367  152674            conf/vldb/Guting94  672980   \n",
       "368  152702    journals/sigmod/Anisimov03  945741   \n",
       "369  152704           conf/vldb/WienerN94  672979   \n",
       "\n",
       "                                                                                                 l_title  \\\n",
       "0                                        World Wide Database - Integrating the Web, CORBA, and Databases   \n",
       "1                                                               XML-Based Information Mediation with MIX   \n",
       "2                                   The Active MultiSync Controller of the Cubetree Storage Organization   \n",
       "3                                                           Building Database-driven Electronic Catalogs   \n",
       "4                                              XML and Electronic Commerce: Enabling the Network Economy   \n",
       "..                                                                                                   ...   \n",
       "365                                                                                      Guest editorial   \n",
       "366                                                                                      Guest editorial   \n",
       "367                                                   GraphDB: Modeling and Querying Graphs in Databases   \n",
       "368  Review of The data warehouse toolkit: the complete guide to dimensional modeling (2nd edition) b...   \n",
       "369                                                       Bulk Loading into an OODB: A Performance Study   \n",
       "\n",
       "                                                                                                 r_title  \\\n",
       "0                                           World Wide Database-integrating the Web, CORBA and databases   \n",
       "1                                                               XML-based information mediation with MIX   \n",
       "2                                   The active MultiSync controller of the cubetree storage organization   \n",
       "3                                                           Building database-driven electronic catalogs   \n",
       "4                                              XML and electronic commerce: enabling the network economy   \n",
       "..                                                                                                   ...   \n",
       "365                                                                                      Guest editorial   \n",
       "366                                                                                      Guest editorial   \n",
       "367                                                   GraphDB: Modeling and Querying Graphs in Databases   \n",
       "368  Review of The data warehouse toolkit: the complete guide to dimensional modeling (2nd edition) b...   \n",
       "369                                                       Bulk Loading into an OODB: A Performance Study   \n",
       "\n",
       "     _sim_score  \n",
       "0      0.811321  \n",
       "1      0.710526  \n",
       "2      0.750000  \n",
       "3      0.744681  \n",
       "4      0.758621  \n",
       "..          ...  \n",
       "365    1.000000  \n",
       "366    1.000000  \n",
       "367    1.000000  \n",
       "368    0.992126  \n",
       "369    1.000000  \n",
       "\n",
       "[1737 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][2]['table'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load data from DBLP-ACM_perfectMapping.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The table below is the correct matching result (ground true table) that can be used for benchmark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_id</th>\n",
       "      <th>r_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conf/sigmod/SlivinskasJS01</td>\n",
       "      <td>375678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conf/sigmod/ChaudhuriDN01</td>\n",
       "      <td>375694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conf/sigmod/RinfretOO01</td>\n",
       "      <td>375669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>conf/sigmod/BreunigKKS01</td>\n",
       "      <td>375672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conf/sigmod/JagadishJOT01</td>\n",
       "      <td>375687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>journals/sigmod/Scholl01</td>\n",
       "      <td>604275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>journals/sigmod/Rosneblatt94</td>\n",
       "      <td>190649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>journals/sigmod/Winslett02b</td>\n",
       "      <td>601871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>journals/sigmod/Labrinidis01</td>\n",
       "      <td>604283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>journals/sigmod/Winslett03</td>\n",
       "      <td>640999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2224 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              l_id    r_id\n",
       "0       conf/sigmod/SlivinskasJS01  375678\n",
       "1        conf/sigmod/ChaudhuriDN01  375694\n",
       "2          conf/sigmod/RinfretOO01  375669\n",
       "3         conf/sigmod/BreunigKKS01  375672\n",
       "4        conf/sigmod/JagadishJOT01  375687\n",
       "...                            ...     ...\n",
       "2219      journals/sigmod/Scholl01  604275\n",
       "2220  journals/sigmod/Rosneblatt94  190649\n",
       "2221   journals/sigmod/Winslett02b  601871\n",
       "2222  journals/sigmod/Labrinidis01  604283\n",
       "2223    journals/sigmod/Winslett03  640999\n",
       "\n",
       "[2224 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def caculate_true_positive(joined_table, true_label_table):\n",
    "    joined_tuples = joined_table[[\"l_id\", \"r_id\"]].to_records(index = False).astype(dtype=[('l_id', 'O'), ('r_id', 'O')])\n",
    "    true_tuples = true_label_table[[\"l_id\", \"r_id\"]].to_records(index = False).astype(dtype=[('l_id', 'O'), ('r_id', 'O')])\n",
    "    return len(np.intersect1d(joined_tuples, true_tuples))\n",
    "true_label_table = pd.read_csv(\"./dataset/library/DBLP-ACM_perfectMapping.csv\", header = 0, encoding=\"ISO-8859-1\", names = ['l_id', 'r_id'])\n",
    "true_label_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Encode result to .plk file and load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_obj = {'result': result, 'l_table' : l_table, 'r_table':r_table}\n",
    "pickle.dump(pickle_obj, open(\"script_0.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_obj = pickle.load(open(\"script_0.pkl\", \"rb\"))\n",
    "temp_result = load_obj['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caculate metrics for result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider that result from load_data_and_test function is the prediction, and the correct matching from above table is the \"ground true labels\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(result, true_label_table):\n",
    "    for i in range(0, len(result)):\n",
    "        for obj_res in result[i]:\n",
    "            obj_res[\"true_positive\"] = caculate_true_positive(obj_res[\"table\"], true_label_table)\n",
    "            obj_res[\"false_positive\"] = len(obj_res[\"table\"]) - obj_res[\"true_positive\"]\n",
    "            obj_res[\"false_negative\"] = len(true_label_table) - obj_res[\"true_positive\"]\n",
    "            obj_res[\"recall\"] = obj_res[\"true_positive\"] / (obj_res[\"true_positive\"] + obj_res[\"false_negative\"])\n",
    "            obj_res[\"precision\"] = obj_res[\"true_positive\"] / (obj_res[\"true_positive\"] + obj_res[\"false_positive\"])\n",
    "            obj_res[\"F1\"] = 2 * obj_res[\"precision\"] * obj_res[\"recall\"] / (obj_res[\"precision\"] + obj_res[\"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(result, true_label_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the caculated metrics from the scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time  num_candidate\n",
      "0    3.833089           4515\n",
      "1   38.655310        2806383\n",
      "2    1.698787          55697\n",
      "3  209.562787         860760\n",
      "\n",
      "\n",
      "   precision    recall        f1       time\n",
      "0   0.851468  0.665018  0.746781  23.681954\n",
      "1   0.845070  0.458633  0.594579  15.376251\n",
      "2   0.912451  0.421763  0.576876   5.057908\n",
      "\n",
      "\n",
      "   precision    recall        f1      time\n",
      "0   0.911005  0.428058  0.582441  1.246634\n",
      "1   0.912366  0.421313  0.576438  0.927507\n",
      "2   0.912745  0.418615  0.573983  0.930105\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(0, len(temp_result)):\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    time_list = []\n",
    "    num_candidate_list = []\n",
    "    for y in range(0, len(temp_result[x])):\n",
    "        precision_list.append(temp_result[x][y][\"precision\"])\n",
    "        recall_list.append(temp_result[x][y][\"recall\"])\n",
    "        f1_list.append(temp_result[x][y][\"F1\"])\n",
    "        time_list.append(temp_result[x][y][\"time\"])\n",
    "        num_candidate_list.append(temp_result[x][y][\"num_candidate\"])\n",
    "    if x > 0:\n",
    "        data_frame = pd.DataFrame({\"precision\": precision_list, \"recall\": recall_list, \"f1\": f1_list, \"time\": time_list})\n",
    "    else: \n",
    "        data_frame = pd.DataFrame({\"time\": time_list, \"num_candidate\": num_candidate_list})\n",
    "    print(data_frame)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first table is comparision of performance of 4 filters: position, prefix, size, suffix. The similarity measure is Jaccard, threshold 0.7.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The second table is comparision of time and accuracy metrics by the change of threshold 0.7 -> 0.8 -> 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The third table is comparision of time and accuracy metrics by the using 3-gram, 4-gram, 5-gram tokenizers with Jaccard similarity measure, threhold 0.8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   precision    recall        f1      time  num_candidate\n",
      "0   0.792288  0.979317  0.875930  9.932187         391289\n",
      "1   0.859917  0.935701  0.896210  6.164150         271802\n",
      "2   0.851468  0.665018  0.746781  4.058825         152755\n",
      "3   0.845070  0.458633  0.594579  2.023184          61095\n",
      "4   0.912451  0.421763  0.576876  1.761235          12121\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_result = result\n",
    "for x in range(0, len(temp_result)):\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    time_list = []\n",
    "    num_candidate_list = []\n",
    "    for y in range(0, len(temp_result[x])):\n",
    "        precision_list.append(temp_result[x][y][\"precision\"])\n",
    "        recall_list.append(temp_result[x][y][\"recall\"])\n",
    "        f1_list.append(temp_result[x][y][\"F1\"])\n",
    "        time_list.append(temp_result[x][y][\"time\"])\n",
    "        num_candidate_list.append(temp_result[x][y][\"num_candidate\"])\n",
    "        data_frame = pd.DataFrame({\"precision\": precision_list, \"recall\": recall_list, \"f1\": f1_list, \"time\": time_list, \"num_candidate\" : num_candidate_list})\n",
    "    print(data_frame)\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6c1d204e62b44b76b6dc89b156b79942",
  "deepnote_persisted_session": {
   "createdAt": "2023-04-09T12:47:31.466Z"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

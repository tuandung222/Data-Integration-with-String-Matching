{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"ef581bdb7d6e47849e5983c0104bd1ea","deepnote_cell_type":"markdown","id":"ewhyFqhtxLZr"},"source":["# Import thư viện"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"3d1cc0bae4934bf6a226d3fd0e662022","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":28,"execution_start":1681025738069,"id":"jgiAa62vETd-","outputId":"3593ab81-608a-4e84-eacd-0a207d0376a5","source_hash":"e837903e"},"outputs":[],"source":["# # Import libraries\n","# !pip install py_stringsimjoin\n","# !pip install py_stringmatching\n","import py_stringsimjoin as ssj\n","import py_stringmatching as sm\n","import pandas as pd\n","import os, sys, time"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"cada0698920b47b8a653061107b4b735","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1,"execution_start":1681025738151,"id":"TLpnj4WlnE2m","source_hash":"8bb54c38"},"outputs":[],"source":["from py_stringmatching.tokenizer.delimiter_tokenizer import DelimiterTokenizer\n","from py_stringmatching.tokenizer.qgram_tokenizer import QgramTokenizer\n","import pandas as pd\n","\n","from py_stringsimjoin.join.cosine_join import cosine_join\n","from py_stringsimjoin.join.dice_join import dice_join\n","from py_stringsimjoin.join.edit_distance_join import edit_distance_join\n","from py_stringsimjoin.join.jaccard_join import jaccard_join\n","from py_stringsimjoin.join.overlap_coefficient_join import overlap_coefficient_join\n","from py_stringsimjoin.join.overlap_join import overlap_join"]},{"cell_type":"markdown","metadata":{"cell_id":"f035eb31416849a390b35f1a1ddf30e6","deepnote_cell_type":"markdown","id":"9GtSl4WOxQQD"},"source":["# Download dataset"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"0db966f47ac246e58a74f389c04766ee","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1,"execution_start":1681025738195,"id":"qIffFjdBte1k","outputId":"02de8763-b711-4300-c2f0-f51cde8b96ea","source_hash":"33db56c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gdown\n","  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gdown) (3.9.0)\n","Requirement already satisfied: beautifulsoup4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gdown) (4.11.1)\n","Requirement already satisfied: requests[socks] in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gdown) (2.28.1)\n","Requirement already satisfied: tqdm in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gdown) (4.64.1)\n","Requirement already satisfied: six in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gdown) (1.16.0)\n","Requirement already satisfied: soupsieve>1.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.26.14)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2.0.4)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n","Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n","Installing collected packages: gdown\n","Successfully installed gdown-4.7.1\n"]},{"name":"stderr","output_type":"stream","text":["Downloading...\n","From: https://github.com/anhaidgroup/py_stringsimjoin/raw/master/benchmarks/example_datasets.tar.gz\n","To: d:\\BTL DM\\Project\\example_datasets.tar.gz\n","\n","  0%|          | 0.00/15.8M [00:00<?, ?B/s]\n","  3%|▎         | 524k/15.8M [00:00<00:08, 1.71MB/s]\n","  7%|▋         | 1.05M/15.8M [00:00<00:09, 1.50MB/s]\n"," 10%|▉         | 1.57M/15.8M [00:00<00:08, 1.61MB/s]\n"," 13%|█▎        | 2.10M/15.8M [00:01<00:08, 1.63MB/s]\n"," 17%|█▋        | 2.62M/15.8M [00:01<00:06, 1.88MB/s]\n"," 20%|█▉        | 3.15M/15.8M [00:01<00:06, 1.93MB/s]\n"," 23%|██▎       | 3.67M/15.8M [00:02<00:06, 1.87MB/s]\n"," 27%|██▋       | 4.19M/15.8M [00:02<00:06, 1.80MB/s]\n"," 30%|██▉       | 4.72M/15.8M [00:02<00:06, 1.69MB/s]\n"," 33%|███▎      | 5.24M/15.8M [00:02<00:05, 1.85MB/s]\n"," 37%|███▋      | 5.77M/15.8M [00:03<00:05, 1.67MB/s]\n"," 40%|███▉      | 6.29M/15.8M [00:03<00:05, 1.79MB/s]\n"," 43%|████▎     | 6.82M/15.8M [00:03<00:05, 1.66MB/s]\n"," 47%|████▋     | 7.34M/15.8M [00:04<00:06, 1.41MB/s]\n"," 50%|████▉     | 7.86M/15.8M [00:04<00:04, 1.67MB/s]\n"," 53%|█████▎    | 8.39M/15.8M [00:04<00:04, 1.67MB/s]\n"," 56%|█████▋    | 8.91M/15.8M [00:05<00:04, 1.63MB/s]\n"," 60%|█████▉    | 9.44M/15.8M [00:05<00:03, 1.75MB/s]\n"," 63%|██████▎   | 9.96M/15.8M [00:05<00:03, 1.66MB/s]\n"," 66%|██████▋   | 10.5M/15.8M [00:06<00:02, 1.87MB/s]\n"," 70%|██████▉   | 11.0M/15.8M [00:06<00:02, 2.04MB/s]\n"," 73%|███████▎  | 11.5M/15.8M [00:06<00:02, 1.81MB/s]\n"," 76%|███████▋  | 12.1M/15.8M [00:07<00:02, 1.70MB/s]\n"," 80%|███████▉  | 12.6M/15.8M [00:07<00:02, 1.37MB/s]\n"," 83%|████████▎ | 13.1M/15.8M [00:08<00:02, 1.08MB/s]\n"," 86%|████████▋ | 13.6M/15.8M [00:08<00:01, 1.25MB/s]\n"," 90%|████████▉ | 14.2M/15.8M [00:08<00:01, 1.35MB/s]\n"," 93%|█████████▎| 14.7M/15.8M [00:09<00:00, 1.47MB/s]\n"," 96%|█████████▋| 15.2M/15.8M [00:09<00:00, 1.35MB/s]\n","100%|█████████▉| 15.7M/15.8M [00:09<00:00, 1.40MB/s]\n","100%|██████████| 15.8M/15.8M [00:10<00:00, 1.57MB/s]\n"]}],"source":["!pip install gdown\n","!gdown https://github.com/anhaidgroup/py_stringsimjoin/raw/master/benchmarks/example_datasets.tar.gz"]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"ff345f038bd6494693a20fd64776cce6","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1681025738240,"id":"VZr5SEIztrhl","source_hash":"c658409"},"outputs":[],"source":["import tarfile\n","# open file\n","file = tarfile.open('example_datasets.tar.gz')\n","# extracting file\n","file.extractall('./example_datasets')\n","file.close()"]},{"cell_type":"code","execution_count":6,"metadata":{"cell_id":"328b2d717f724e63851e427b43f238e7","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1,"execution_start":1681025738282,"id":"dBVKS4dLsiNJ","source_hash":"3511d469"},"outputs":[],"source":["scenarios_list = [\n","        {\n","            \"dataset_name\": \"anime\",\n","            \"ltable\": [\"anime\", \"A.csv\"],\n","            \"rtable\": [\"anime\", \"B.csv\"],\n","            \"ltable_encoding\": \"utf-8\",\n","            \"rtable_encoding\": \"utf-8\",\n","            \"l_id_attr\": \"ID\",\n","            \"r_id_attr\": \"ID\",\n","            \"l_join_attr\": \"Title\",\n","            \"r_join_attr\": \"Title\",\n","            \"tokenizers\": [\"2_GRAM\"],                                  \n","            \"sim_measure_types\": [\"JACCARD\"],\n","            \"thresholds\": [0.7],\n","            \"n_jobs\": [1],\n","            \"scale_filters\": [\"POSITION_FILTER\", \"OVERLAP_FILTER\", \"PREFIX_FILTER\", \"SIZE_FILTER\", \"SUFFIX_FILTER\"],\n","            \"sim_funcs\": [\"JACCARD\"]\n","    }]"]},{"cell_type":"markdown","metadata":{"cell_id":"a5fc7955cb7b43a38ff50f5c16b0b098","deepnote_cell_type":"markdown","id":"JHpWmihVxWCq"},"source":["# Define measure and tokenizer"]},{"cell_type":"code","execution_count":7,"metadata":{"cell_id":"67c89af5fd2a48079c36dbe2d769ac05","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1,"execution_start":1681025738328,"id":"hoM6M95onRDT","source_hash":"2451014b"},"outputs":[],"source":["JOIN_FUNCTIONS = {'COSINE': cosine_join,\n","                  'DICE': dice_join,\n","                  'EDIT_DISTANCE': edit_distance_join,\n","                  'JACCARD': jaccard_join,\n","                  'OVERLAP': overlap_join,\n","                  'OVERLAP_COEFFICIENT': overlap_coefficient_join}\n","\n","TOKENIZERS = {'SPACE_DELIMITER': DelimiterTokenizer(delim_set=[' '],\n","                                                    return_set=True),\n","              '2_GRAM': QgramTokenizer(qval=2, padding=False, return_set=True),\n","              '3_GRAM': QgramTokenizer(qval=3, padding=False, return_set=True),\n","              '2_GRAM_BAG': QgramTokenizer(qval=2),\n","              '3_GRAM_BAG': QgramTokenizer(qval=3)\n","            }"]},{"cell_type":"markdown","metadata":{"cell_id":"905cbdc7f9644123829996c94bbd613b","deepnote_cell_type":"markdown","id":"Gt7xduvIx8ce"},"source":["# Define filters"]},{"cell_type":"code","execution_count":8,"metadata":{"cell_id":"227a5bfcc3734d27beba17c0edfb1a20","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1681025738328,"id":"Z3oL9Sr4nr5U","source_hash":"ab932efc"},"outputs":[],"source":["FILTERS = {\n","    \"OVERLAP_FILTER\": ssj.OverlapFilter,\n","    \"SIZE_FILTER\": ssj.SizeFilter,\n","    \"PREFIX_FILTER\": ssj.PrefixFilter,\n","    \"POSITION_FILTER\": ssj.PositionFilter,\n","    \"SUFFIX_FILTER\": ssj.SuffixFilter\n","}"]},{"cell_type":"markdown","metadata":{"cell_id":"56e7f9ddabd840eebeb44ef8311acf48","deepnote_cell_type":"text-cell-h1","formattedRanges":[]},"source":["# Define Sim_function"]},{"cell_type":"code","execution_count":9,"metadata":{"cell_id":"44efb54c585a4e7da02c046936cb4b24","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":7,"execution_start":1681025738378,"source_hash":"83926d71"},"outputs":[],"source":["SIM_FUNC = {\n","    'COSINE': sm.Cosine().get_sim_score,\n","    'DICE': sm.Dice().get_sim_score,\n","    'JACCARD': sm.Jaccard().get_sim_score,\n","    'OVERLAP_COEFFICIENT': sm.OverlapCoefficient().get_sim_score,\n","    'LEVENSHTEIN': sm.Levenshtein().get_sim_score,\n","    'TF-IDF': sm.TfIdf,\n","}"]},{"cell_type":"markdown","metadata":{"cell_id":"930899e860a04c3890d013a72df5433e","deepnote_cell_type":"markdown","id":"hwWsTSjpyAFU"},"source":["# Set directory"]},{"cell_type":"code","execution_count":10,"metadata":{"cell_id":"7bea85508a6b4b6bab38993d7d200ea7","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6,"execution_start":1681025738450,"id":"J-VYzWpDncyZ","source_hash":"cb516d1c"},"outputs":[],"source":["# path where datasets are present                 \n","BASE_PATH = os.sep.join([os.getcwd(), 'example_datasets', 'example_datasets'])\n","\n","# join scenarios json file. If you need to perform benchmark on a new dataset,\n","# add a entry for that dataset in the json file.\n","JOIN_SCENARIOS_FILE = 'join_scenarios.json'\n","\n","# datasets that need to be skipped from benchmarking\n","EXCLUDE_DATASETS = []\n","\n","# number of times to run each benchmark\n","NUMBER_OF_EXECUTIONS = 1\n","\n","# benchmark output directory\n","OUTPUT_DIR = '_benchmark_results'"]},{"cell_type":"code","execution_count":11,"metadata":{"cell_id":"0e5d38a5af544e6caa30a40aeece7922","colab":{"base_uri":"https://localhost:8080/","height":35},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6,"execution_start":1681025738450,"id":"wWX4a5NIv8lh","outputId":"27d40785-b61b-4069-f8b6-41043e777b8f","source_hash":"4462351f"},"outputs":[{"data":{"text/plain":["'/work/example_datasets/example_datasets'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["BASE_PATH"]},{"cell_type":"markdown","metadata":{"cell_id":"e7dc67c9bd4047aaa31e5737d4b4fe57","deepnote_cell_type":"markdown","id":"-nfu1SRgyDAd"},"source":["# Class JoinScenario"]},{"cell_type":"code","execution_count":12,"metadata":{"cell_id":"b583be2abca54f42a9b8e84223b607b2","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6,"execution_start":1681025738451,"id":"5EnIdkIkpfpE","source_hash":"aaee761c"},"outputs":[],"source":["class JoinScenario:\n","    def __init__(self, dataset_name, ltable, rtable,\n","                 ltable_encoding, rtable_encoding, l_id_attr, r_id_attr,\n","                 l_join_attr, r_join_attr, tokenizers,\n","                 sim_measure_types, thresholds, n_jobs, scale_filters, sim_funcs):\n","        self.dataset_name = dataset_name \n","        self.ltable = os.sep.join(ltable)\n","        self.rtable = os.sep.join(rtable)\n","        self.ltable_encoding = ltable_encoding\n","        self.rtable_encoding = rtable_encoding\n","        self.l_id_attr = l_id_attr\n","        self.r_id_attr = r_id_attr\n","        self.l_join_attr = l_join_attr\n","        self.r_join_attr = r_join_attr\n","        self.tokenizers = tokenizers\n","        self.sim_measure_types = sim_measure_types\n","        self.thresholds = thresholds\n","        self.n_jobs = n_jobs\n","        self.scale_filters = scale_filters\n","        self.sim_funcs = sim_funcs"]},{"cell_type":"code","execution_count":13,"metadata":{"cell_id":"04f1491a0e844acba3ddd7bbc45098ab","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":7,"execution_start":1681025738459,"id":"-Y9DhddJphGg","source_hash":"9f5d76d0"},"outputs":[],"source":["import json\n","def load_join_scenarios():\n","\n","    #!!!!!!!!!!!!!!!\n","    # fp = open(JOIN_SCENARIOS_FILE, 'r')\n","    # scenarios = json.load(fp)['scenarios']\n","    # fp.close()\n","    scenarios = scenarios_list\n","\n","    join_scenarios = []\n","    for sc in scenarios:\n","        join_scenario = JoinScenario(sc['dataset_name'], \n","                                     sc['ltable'], sc['rtable'],\n","                                     sc['ltable_encoding'], sc['rtable_encoding'], \n","                                     sc['l_id_attr'], sc['r_id_attr'],\n","                                     sc['l_join_attr'], sc['r_join_attr'],\n","                                     sc['tokenizers'], sc['sim_measure_types'],\n","                                     sc['thresholds'], sc['n_jobs'],\n","                                     sc['scale_filters'],\n","                                     sc['sim_funcs']\n","                                     )\n","        join_scenarios.append(join_scenario)\n","    return join_scenarios"]},{"cell_type":"code","execution_count":14,"metadata":{"cell_id":"fdcf47b793314724a0fed1c7b324acd1","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":24,"execution_start":1681025738468,"id":"FYe91P2jqaR9","source_hash":"cce324b3"},"outputs":[],"source":["def load_data_and_test():\n","    if not os.path.exists(OUTPUT_DIR):\n","        os.makedirs(OUTPUT_DIR)\n","    # load scenarios\n","    scenarios = load_join_scenarios()\n","    output_header = ','.join(['left join attr', 'right join attr', \n","                              'similarity measure type', 'tokenizer',\n","                        'threshold', 'n_jobs', 'candset size', 'avg time']) \n","    for scenario in scenarios:\n","        if scenario.dataset_name in EXCLUDE_DATASETS: continue\n","        ltable_path = os.sep.join([BASE_PATH, scenario.ltable])\n","        rtable_path = os.sep.join([BASE_PATH, scenario.rtable])\n","        out_file_path = os.sep.join([OUTPUT_DIR, scenario.dataset_name])\n","        add_header = not os.path.exists(out_file_path)\n","        output_file = open(out_file_path, 'a')        \n","        if add_header:\n","            output_file.write('%s\\n' % output_header)\n","        # load input tables for the scenario\n","        ltable = pd.read_csv(ltable_path, encoding=scenario.ltable_encoding)\n","        rtable = pd.read_csv(rtable_path, encoding=scenario.rtable_encoding)\n","\n","        test(scenario, output_file, ltable, rtable)\n","    \n","    output_file.close()"]},{"cell_type":"code","execution_count":15,"metadata":{"cell_id":"4a3301028d5d4fda8580f04da7397f23","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":36,"execution_start":1681025738503,"id":"heoCvFWbq6Jq","source_hash":"3419b572"},"outputs":[],"source":["from itertools import product\n","def test(scenario, output_file, ltable, rtable):\n","    total_info_obj = product(\n","        scenario.sim_funcs,\n","        scenario.sim_measure_types, \n","        scenario.tokenizers,\n","        scenario.scale_filters,\n","        scenario.thresholds,\n","        scenario.n_jobs\n","        )\n","    for sim_funcs, sim_measure_type, tokenizer, sclale_filter, threshold, n_jobs in total_info_obj:\n","        if tokenizer in [\"SPACE_DELIMITER\"] and sim_measure_type != 'EDIT_DISTANCE': continue\n","\n","        sim_func = SIM_FUNC[sim_funcs]\n","        # tok = TOKENIZERS['tokenizer']\n","        # sclale_filter = \"SIZE_FILTER\"\n","        # join_fn = JOIN_FUNCTIONS[sim_measure_type]\n","        tok = TOKENIZERS['3_GRAM']\n","        if sclale_filter == \"OVERLAP_FILTER\":\n","            s_filter = FILTERS[sclale_filter](tok, overlap_size=1, comp_op='>=', allow_missing=False)\n","        else: \n","            s_filter = FILTERS[sclale_filter](tok, sim_measure_type, threshold, \\\n","                    allow_empty=True, allow_missing=False)\n","        \n","        if sim_measure_type ==  'EDIT_DISTANCE':\n","            args = (threshold, '<=', False, None, None, 'l_', 'r_', True,\n","                                    n_jobs, tok)\n","        elif sim_measure_type == 'OVERLAP':\n","            args = (tok, threshold, '>=', False, None, None, 'l_', 'r_',\n","                                    True, n_jobs)     \n","        else:\n","            args = (tok, threshold, '>=', True, False, None, None, 'l_', 'r_',\n","                                    True, n_jobs)\n","        print(tokenizer)\n","        ####Caculate time\n","        cumulative_time = 0\n","        candset_size = 0\n","        for i in range(NUMBER_OF_EXECUTIONS):\n","            start_time = time.time()\n","            ###Trước khi join phải apply filter, Apply chỗ này thay join fn bằng apply_matcher\n","            candidate_set = s_filter.filter_tables(\n","                ltable, rtable, \n","                scenario.l_id_attr, scenario.r_id_attr,\n","                scenario.l_join_attr, scenario.r_join_attr,\n","                l_out_attrs=None, r_out_attrs=None, \n","                l_out_prefix='l_', r_out_prefix='r_', \n","                n_jobs=n_jobs, show_progress=True)\n","            C = ssj.apply_matcher(candidate_set, \n","                'l_'+scenario.l_id_attr, 'r_'+scenario.r_id_attr, \\\n","                ltable, rtable, \n","                scenario.l_id_attr, scenario.r_id_attr, \n","                scenario.l_join_attr, scenario.r_join_attr, \n","                tokenizer = tok, \n","                sim_function = sim_func, \n","                threshold = threshold,\n","                comp_op='>=', allow_missing=False, \n","                l_out_attrs=[scenario.l_join_attr], r_out_attrs=[scenario.r_join_attr], \n","                l_out_prefix='l_', r_out_prefix='r_', \n","                out_sim_score=True, n_jobs=n_jobs, show_progress=True) \n","            cumulative_time += (time.time() - start_time)\n","            candset_size = len(C)\n","            avg_time_elapsed = float(cumulative_time) / float(NUMBER_OF_EXECUTIONS)      \n","            output_record = ','.join([str(scenario.l_join_attr), str(scenario.r_join_attr), \n","                                                  str(sim_measure_type), str(tokenizer),\n","                                                  str(threshold), str(n_jobs),\n","                                                  str(candset_size), str(avg_time_elapsed)])\n","            print(C[[\"_id\", 'l_'+scenario.l_join_attr, 'r_'+scenario.r_join_attr, \"_sim_score\"]])\n","            output_file.write('%s\\n' % output_record)\n","                \n","   \n"]},{"cell_type":"code","execution_count":16,"metadata":{"cell_id":"2a4a8005b4274f15ab84b7f441d15b3c","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1639060,"execution_start":1681025738545,"id":"36unYnqyshY_","outputId":"f81010a7-cc50-479a-c04b-2db9d9b9fe80","output_cleared":false,"source_hash":"aa8006fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["2_GRAM\n","Warning: No valid output stream.\n","Warning: No valid output stream.\n","        _id                                                l_Title  \\\n","0         6                Hidamari Sketch: Sae Hiro Sotsugyou-hen   \n","1         9                             To Aru Kagaku no Railgun S   \n","2        12                                      Tamako Love Story   \n","3        15                                             Working!!!   \n","4        16                                              Working!!   \n","...     ...                                                    ...   \n","2721  11832  Wellber no Monogatari: Sisters of Wellber Dai ni Maku   \n","2722  11857                                          Dragon Ball Z   \n","2723  11858                                            Dragon Ball   \n","2724  11866                         Hentai Ouji to Warawanai Neko.   \n","2725  11896                            Otome wa Boku ni Koishiteru   \n","\n","                                          r_Title  _sim_score  \n","0         Hidamari Sketch: Sae Hiro Sotsugyou-hen    1.000000  \n","1                       Toaru Kagaku no Railgun S    0.740741  \n","2                               Tamako Love Story    1.000000  \n","3                                      Working!!!    1.000000  \n","4                                      Working!!!    0.875000  \n","...                                           ...         ...  \n","2721    Wellber no Monogatari: Sisters of Wellber    0.755556  \n","2722                               Dragon Ball GT    0.769231  \n","2723                               Dragon Ball GT    0.750000  \n","2724  Hentai Ouji to Warawanai Neko.: Henneko BBS    0.710526  \n","2725          Otome wa Boku ni Koishiteru Special    0.757576  \n","\n","[2726 rows x 4 columns]\n","2_GRAM\n","Warning: No valid output stream.\n","Warning: No valid output stream.\n","          _id                                                l_Title  \\\n","0        1652                Hidamari Sketch: Sae Hiro Sotsugyou-hen   \n","1        3101                             To Aru Kagaku no Railgun S   \n","2        4202                                      Tamako Love Story   \n","3        4931                                             Working!!!   \n","4        4959                                              Working!!   \n","...       ...                                                    ...   \n","2709  3739629  Wellber no Monogatari: Sisters of Wellber Dai ni Maku   \n","2710  3754809                                          Dragon Ball Z   \n","2711  3754810                                            Dragon Ball   \n","2712  3760354                         Hentai Ouji to Warawanai Neko.   \n","2713  3771078                            Otome wa Boku ni Koishiteru   \n","\n","                                          r_Title  _sim_score  \n","0         Hidamari Sketch: Sae Hiro Sotsugyou-hen    1.000000  \n","1                       Toaru Kagaku no Railgun S    0.740741  \n","2                               Tamako Love Story    1.000000  \n","3                                      Working!!!    1.000000  \n","4                                      Working!!!    0.875000  \n","...                                           ...         ...  \n","2709    Wellber no Monogatari: Sisters of Wellber    0.755556  \n","2710                               Dragon Ball GT    0.769231  \n","2711                               Dragon Ball GT    0.750000  \n","2712  Hentai Ouji to Warawanai Neko.: Henneko BBS    0.710526  \n","2713          Otome wa Boku ni Koishiteru Special    0.757576  \n","\n","[2714 rows x 4 columns]\n","2_GRAM\n","Warning: No valid output stream.\n","Warning: No valid output stream.\n","         _id                                                l_Title  \\\n","0         94                Hidamari Sketch: Sae Hiro Sotsugyou-hen   \n","1        139                             To Aru Kagaku no Railgun S   \n","2        183                                      Tamako Love Story   \n","3        198                                             Working!!!   \n","4        199                                              Working!!   \n","...      ...                                                    ...   \n","2721  143202  Wellber no Monogatari: Sisters of Wellber Dai ni Maku   \n","2722  143828                                          Dragon Ball Z   \n","2723  143843                                            Dragon Ball   \n","2724  144079                         Hentai Ouji to Warawanai Neko.   \n","2725  144421                            Otome wa Boku ni Koishiteru   \n","\n","                                          r_Title  _sim_score  \n","0         Hidamari Sketch: Sae Hiro Sotsugyou-hen    1.000000  \n","1                       Toaru Kagaku no Railgun S    0.740741  \n","2                               Tamako Love Story    1.000000  \n","3                                      Working!!!    1.000000  \n","4                                      Working!!!    0.875000  \n","...                                           ...         ...  \n","2721    Wellber no Monogatari: Sisters of Wellber    0.755556  \n","2722                               Dragon Ball GT    0.769231  \n","2723                               Dragon Ball GT    0.750000  \n","2724  Hentai Ouji to Warawanai Neko.: Henneko BBS    0.710526  \n","2725          Otome wa Boku ni Koishiteru Special    0.757576  \n","\n","[2726 rows x 4 columns]\n","2_GRAM\n","Warning: No valid output stream.\n","Warning: No valid output stream.\n","          _id                                                l_Title  \\\n","0        1305                Hidamari Sketch: Sae Hiro Sotsugyou-hen   \n","1        2469                             To Aru Kagaku no Railgun S   \n","2        4323                                      Tamako Love Story   \n","3        5515                                             Working!!!   \n","4        5814                                              Working!!   \n","...       ...                                                    ...   \n","2721  4925877  Wellber no Monogatari: Sisters of Wellber Dai ni Maku   \n","2722  4935106                                          Dragon Ball Z   \n","2723  4935155                                            Dragon Ball   \n","2724  4944107                         Hentai Ouji to Warawanai Neko.   \n","2725  4962521                            Otome wa Boku ni Koishiteru   \n","\n","                                          r_Title  _sim_score  \n","0         Hidamari Sketch: Sae Hiro Sotsugyou-hen    1.000000  \n","1                       Toaru Kagaku no Railgun S    0.740741  \n","2                               Tamako Love Story    1.000000  \n","3                                      Working!!!    1.000000  \n","4                                      Working!!!    0.875000  \n","...                                           ...         ...  \n","2721    Wellber no Monogatari: Sisters of Wellber    0.755556  \n","2722                               Dragon Ball GT    0.769231  \n","2723                               Dragon Ball GT    0.750000  \n","2724  Hentai Ouji to Warawanai Neko.: Henneko BBS    0.710526  \n","2725          Otome wa Boku ni Koishiteru Special    0.757576  \n","\n","[2726 rows x 4 columns]\n","2_GRAM\n","Warning: No valid output stream.\n","Warning: No valid output stream.\n","         _id                                                         l_Title  \\\n","0        332                             Mobile Suit Gundam 00 Second Season   \n","1        393                                                        One Outs   \n","2        405                           Kara no Kyoukai Movie 4: Garan no Dou   \n","3        503                                             Hunter x Hunter OVA   \n","4        504                                             Hunter x Hunter OVA   \n","...      ...                                                             ...   \n","2643  582774                                                     Doujin Work   \n","2644  582808                                             True Tears Epilogue   \n","2645  582983                              Shinmai Maou no Testament Specials   \n","2646  583290  Digimon Xros Wars: Aku no Death General to Shichinin no Oukoku   \n","2647  583543                                              Steel Angel Kurumi   \n","\n","                                                           r_Title  _sim_score  \n","0                              Mobile Suit Gundam 00 Second Season    1.000000  \n","1                                                         One Outs    1.000000  \n","2                                  Kara no Kyoukai 4: Garan no Dou    0.757576  \n","3                                                  Hunter x Hunter    0.750000  \n","4                                              Hunter x Hunter OVA    1.000000  \n","...                                                            ...         ...  \n","2643                                                   Doujin Work    1.000000  \n","2644                                           True Tears Epilogue    1.000000  \n","2645                                     Shinmai Maou no Testament    0.718750  \n","2646  Digimon Xros Wars: Aku no Death General to Nanatsu no Oukoku    0.712121  \n","2647                                            Steel Angel Kurumi    1.000000  \n","\n","[2648 rows x 4 columns]\n"]}],"source":["load_data_and_test()"]},{"cell_type":"code","execution_count":17,"metadata":{"cell_id":"20bef875ff95465d8ce8ac3094286f0c","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":12,"execution_start":1681027377606,"source_hash":"b623e53d"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":17,"metadata":{"cell_id":"ad0903dd54b046e9afec7531a431f90e","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1,"execution_start":1681027377621,"source_hash":"b623e53d"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=c080558f-d0ef-4c01-aae2-20b2147b87a6' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"6c1d204e62b44b76b6dc89b156b79942","deepnote_persisted_session":{"createdAt":"2023-04-09T12:47:31.466Z"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
